{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_genetator(starting_date):\n",
    "    date=datetime.datetime.strptime(starting_date,\"%d.%m.%Y\")\n",
    "    while True:\n",
    "        yield date\n",
    "        date-=datetime.timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"../NewsParsing\"\n",
    "publishers=[\"kommersant\",\"lenta\",\"interfax\",\"gazeta\",\"rain\"]\n",
    "starting_date=\"09.11.2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    data=[]\n",
    "    for date in date_genetator(starting_date):\n",
    "        tmp=[]\n",
    "        for pub in publishers:\n",
    "            try:\n",
    "                fie=os.path.join(data_dir,pub,datetime.datetime.strftime(date,\"%Y-%m-%d.csv\"))\n",
    "                tmp.append(pd.read_csv(fie, encoding='utf-8'))\n",
    "                tmp[-1][\"publisher\"]=pub\n",
    "            except:\n",
    "                print(\"Real end date:\", datetime.datetime.strftime(date,\"%Y-%m-%d\"))\n",
    "                return data\n",
    "        data+=tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real end date: 2015-12-28\n"
     ]
    }
   ],
   "source": [
    "raw_data=build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat(raw_data, ignore_index=True)\n",
    "data=data[data[\"text\"].notna() & data[\"title\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"id\"]=data[\"publisher\"]+\"_\"+data[\"url\"].apply(lambda x: x.rstrip('/').split('.ru/',1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"fdate\"]=data[\"date\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_data=data.sample(frac=1,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_thr=ceil(len(sh_data)*0.8)\n",
    "test_thr=ceil(len(sh_data)*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "806852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['train','validate','test']\n",
    "fd=\"./headline_dataset\"\n",
    "\n",
    "writers=[open(os.path.join(fd,n+'.jsonl'),encoding='utf-8',mode='w') for n in names]\n",
    "\n",
    "for idx, row in sh_data.iterrows():\n",
    "    split=(idx>val_thr)+(idx>test_thr)\n",
    "    tow={'target':row['title'],\n",
    "         'source':row['text'].replace('\\\\n',' ')}\n",
    "    json.dump(tow,writers[split], ensure_ascii=False)\n",
    "    writers[split].write('\\n')\n",
    "\n",
    "for w in writers:\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 'СКР возбудил дело по статье «Убийство» после трагедии с псковскими подростками',\n",
       " 'source': 'Следственное управление СКР по Псковской области возбудило дело по ст. 105 УК РФ (убийство) в отношении неустановленного лица после того, как в частном доме поселка Струги Красные были обнаружены тела 15-летних юноши и девушки. Официальный представитель ведомства Юрий Зайцев отметил, что «до установления всех обстоятельств преступления дело будет расследоваться по этой статье». «Если в рамках расследования будет установлено, что произошло самоубийство, дело будет закрыто»,— приводит ТАСС его слова. Напомним, 14 ноября в поселке Струги Красные 15-летние юноша и девушка забаррикадировались в частном доме и обстреливали полицейских из охотничьего ружья. В течение нескольких часов подростки вели прямые видеотрансляции происходящего в осажденном бойцами СОБРа здании в социальных сетях. После штурма в доме были обнаружены тела школьников с огнестрельными ранами. По официальному заявлению следствия они покончили с собой. Подробнее о трагедии читайте в материале «Ъ» «Уходить буду красиво».'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['train','validate','test']\n",
    "fd=\"./headline_dataset\"\n",
    "td=\"./headline_parts\"\n",
    "size=2000\n",
    "pn='ruhead'\n",
    "\n",
    "for n in names:\n",
    "    with open(os.path.join(fd,n+'.jsonl'),encoding='utf-8') as f:\n",
    "        buf=[]\n",
    "        for idx, line in enumerate(f):\n",
    "            if idx>0 and idx%size==0:\n",
    "                with open(os.path.join(td,pn+'.'+n+'.'+str(idx//size-1)+'.json'), encoding='utf-8', mode='w') as pf:\n",
    "                          json.dump(buf, pf, ensure_ascii=False)\n",
    "                          buf=[]\n",
    "            tmp=json.loads(line, encoding='utf-8')\n",
    "            buf.append({\n",
    "                'tgt':[[i.text for i in tokenize(j.text)] for j in sentenize(tmp['target'])],\n",
    "                'src':[[i.text for i in tokenize(j.text)] for j in sentenize(tmp['source'])]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
